## What I Learned

Throughout this project, I developed a comprehensive understanding of how to handle unstructured text data and apply unsupervised learning techniques for document clustering. Here's a breakdown of key learnings from each phase:

---

### DMW exp 01 – Text Cleaning & Preprocessing
- Learned to **clean raw text** by removing stopwords, punctuations, and special characters.
- Applied **lemmatization** to reduce words to their root forms.
- Understood the importance of preprocessing to reduce noise in textual datasets.

---

### DMW exp 02 – Feature Extraction
- Explored different methods for **text vectorization** such as:
  - **TF-IDF** (Term Frequency-Inverse Document Frequency)
  - **Bag of Words**
- Learned how to **numerically represent text data** for machine learning algorithms.

---

### DMW exp 03 – Exploratory Data Analysis (EDA)
- Performed **descriptive statistics** on document lengths and word distributions.
- Created **word clouds**, **class distribution plots**, and **n-gram analyses**.
- Understood how to extract **meaningful insights from text corpora** before modeling.

---

### DMW exp 04 – K-Means Clustering
- Implemented **K-Means** to group similar documents.
- Learned how to choose the optimal number of clusters using the **Elbow Method** and **Silhouette Score**.
- Visualized results and saw how documents form natural groupings.

---

### DMW exp 05 – DBSCAN & Outlier Detection
- Applied **DBSCAN** to detect dense regions and isolate outliers in the dataset.
- Learned the impact of **eps** and **min_samples** on clustering performance.
- Compared DBSCAN to K-Means in terms of flexibility and noise handling.

---

### DMW exp 06 – Dimensionality Reduction & Visualization
- Used **PCA (Principal Component Analysis)** and **t-SNE** to reduce high-dimensional TF-IDF vectors for visualization.
- Created **2D plots** to visually assess cluster separation.
- Gained intuition on how document vectors relate in space.

---

### DMW exp 07 – Model Evaluation
- Evaluated clustering performance using:
  - **Silhouette Score**
  - **Davies-Bouldin Index**
  - **Calinski-Harabasz Score**
- Reflected on the strengths and weaknesses of different clustering algorithms.
- Discussed **real-world applications** and **future enhancements** (e.g., deep learning, multi-label clustering).

---

### Overall Takeaways
- Mastered the end-to-end **unsupervised text mining workflow**.
- Learned to transform messy textual data into **actionable clusters**.
- Understood how **NLP + machine learning** together reveal hidden structure in language.
- Experienced the challenge of working without labels (true to unsupervised learning) and the importance of **visual and statistical validation**.
